{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дискурсивные формулы\n",
    "## На данный момент:\n",
    "+ 37 текстов\n",
    "+ 113933 псевдоклаузы\n",
    "+ Доля класса 1 (формулы) - 2.5 %\n",
    "+ Доля класса 0 (не формулы) - 97.5 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "\n",
    "class Profiler():\n",
    "    def __enter__(self):\n",
    "        self._startTime = time.time()\n",
    "         \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        print (\"Время обучения: {:.3f} секунд\".format(time.time() - self._startTime))\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113933, 27)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_data.csv', encoding = 'utf-8-sig', sep = ';')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = pd.read_csv('train_target.csv',encoding = 'utf-8-sig', sep = ';' )\n",
    "target.ix[data['First'] == 0,'\"Target\"'] = 0\n",
    "y = np.array(target['\"Target\"']).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля формул в выборке:\n",
      "0.0250322557995\n",
      "Доля НЕ формул в выборке:\n",
      "0.974967744201\n"
     ]
    }
   ],
   "source": [
    "print('Доля формул в выборке:')\n",
    "print(target['\"Target\"'].value_counts()[1]/len(target))\n",
    "print('Доля НЕ формул в выборке:')\n",
    "print(target['\"Target\"'].value_counts()[0]/len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100002, 27), (13931, 27))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в качестве теста - взять несколько текстов\n",
    "test_texts = {'Puzhaeva_Гоголь. Игроки',\n",
    "             'Petrushevskaya_uroki_muzyki_ev_prov',\n",
    "             'Yad_EV_prov'}\n",
    "criterion = data['\"Text_id\"'].map(lambda x: x in test_texts)\n",
    "test_indices = data[criterion].index.tolist()\n",
    "texts_test = data[['\"Text_id\"','Text']][criterion]\n",
    "X_test = data.loc[test_indices,:]\n",
    "y_test = np.array(target.loc[test_indices,:]).reshape(-1,)\n",
    "X_train = data.drop(test_indices)\n",
    "y_train = np.array(target.drop(test_indices)).reshape(-1,)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# векторизаторы по словам и символам\n",
    "count = CountVectorizer(min_df = 10, ngram_range = (1,2))\n",
    "count_char = CountVectorizer(min_df = 10, ngram_range = (3,4),analyzer='char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# фиттим на всех данных, трансформируем текст клауз тренировочной и тестовой выборок, а также все данные \n",
    "count.fit(data['Text'])\n",
    "count_train = count.transform(X_train['Text'])\n",
    "count_test = count.transform(X_test['Text'])\n",
    "count_texts = count.transform(data['Text'])\n",
    "\n",
    "count_char.fit(data['Text'])\n",
    "count_char_train = count_char.transform(X_train['Text'])\n",
    "count_char_test = count_char.transform(X_test['Text'])\n",
    "count_char_texts = count_char.transform(data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# удаляем ненужные колонки, трансформируем наши существующие признаки в разреженную матрицу, чтобы объединить с существующими\n",
    "# векторизированными признаками\n",
    "X_train = X_train.drop(['Text','\"Text_id\"'],axis=1)\n",
    "X_test = X_test.drop(['Text','\"Text_id\"'],axis=1)\n",
    "X_train_sparse = csr_matrix(X_train)\n",
    "X_test_sparse = csr_matrix(X_test)\n",
    "alldata_sparse = csr_matrix(data.drop(['Text','\"Text_id\"'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<100002x28696 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 3530359 stored elements in COOrdinate format>,\n",
       " <13931x28696 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 473828 stored elements in COOrdinate format>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объединение матриц\n",
    "X_train_count = hstack((count_train,count_char_train,X_train_sparse))\n",
    "X_test_count = hstack((count_test,count_char_test,X_test_sparse))\n",
    "data_count = hstack((count_texts,count_char_texts,alldata_sparse))\n",
    "\n",
    "X_train_count,X_test_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100002, 2142), (13931, 2142))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = count.get_feature_names() + count_char.get_feature_names() + list(data.columns)\n",
    "\n",
    "# вычисляем ненужные признаки (да здравствует l1-регуляризация)\n",
    "logit_preproc = LogisticRegression(class_weight={1:30,0:1},random_state=seed,penalty='l1',solver='liblinear')\n",
    "logit_preproc.fit(X_train_count,y_train)\n",
    "\n",
    "# убираем ненужные признаки\n",
    "X_train_imp = X_train_count.tocsr()[:,np.nonzero(logit_preproc.coef_[0])[0]]\n",
    "X_test_imp = X_test_count.tocsr()[:,np.nonzero(logit_preproc.coef_[0])[0]]\n",
    "data_imp = data_count.tocsr()[:,np.nonzero(logit_preproc.coef_[0])[0]]\n",
    "fs_clean = [fs[i] for i in np.nonzero(logit_preproc.coef_[0])[0]]\n",
    "X_train_imp.shape, X_test_imp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['\"Text_id\"', 'Text', 'Len', 'Subject', 'Object', 'Predicate',\n",
       "       'Emotions', 'Imperative', 'Question', 'First', 'NOUN', 'ADJF', 'ADJS',\n",
       "       'COMP', 'VERB', 'INFN', 'PRTF', 'PRTS', 'GRND', 'NUMR', 'ADVB', 'NPRO',\n",
       "       'PRED', 'PREP', 'CONJ', 'PRCL', 'INTJ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# правиловый\n",
    "# первые в реплике перед восклиц знаком и вопрос знаком, если там есть союзы или частицы\n",
    "from copy import deepcopy\n",
    "pred_base = deepcopy(target)\n",
    "pred_base['\"Target\"'] = 0\n",
    "pred_base.loc[X_test.loc[(X_test['First'] == 1) & ((X_test['Emotions'] == 1) | (X_test['Question'] == 1)) &\n",
    "            ((X_test['PRCL'] != 0) | (X_test['CONJ'] != 0))].index,'\"Target\"'] = 1\n",
    "pred_base = np.array(pred_base.loc[X_test.index,'\"Target\"']).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.97      0.98     13594\n",
      "          1       0.18      0.25      0.21       337\n",
      "\n",
      "avg / total       0.96      0.95      0.96     13931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "isolforest = IsolationForest(random_state=seed)\n",
    "isolforest.fit(X_train_count,y_train)\n",
    "out_pred = isolforest.predict(X_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.92      0.95     13594\n",
      "          1       0.00      0.00      0.00       337\n",
      "\n",
      "avg / total       0.95      0.90      0.92     13931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_pred[out_pred == 1] = 0\n",
    "out_pred[out_pred == -1] = 1\n",
    "print(classification_report(y_test,out_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение нескольких классификаторов на данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# кроссвалидация по пяти фолдам\n",
    "skf = StratifiedKFold(n_splits = 5, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=300,\n",
    "                             criterion='entropy',\n",
    "                             min_samples_leaf=5,\n",
    "                             class_weight = {1:30,0:1},\n",
    "                             random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   48.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.0min finished\n"
     ]
    }
   ],
   "source": [
    "cv_pred = cross_val_predict(forest, X_train_imp, y_train, cv = skf, verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8388\n",
      "8076\n"
     ]
    }
   ],
   "source": [
    "# удаление предсказанных формул, находящихся после третьей псевдоклаузы - по теоретическим соображениям\n",
    "print(np.sum(cv_pred))\n",
    "idx = X_train['First'].index\n",
    "for i,pr in enumerate(cv_pred):\n",
    "    if X_train['First'][idx[i]] == 0:\n",
    "        cv_pred[i] = 0\n",
    "print(np.sum(cv_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.934211315774\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.94      0.97     97487\n",
      "          1       0.25      0.80      0.38      2515\n",
      "\n",
      "avg / total       0.98      0.93      0.95    100002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# на кросс-валидации\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_train, cv_pred))\n",
    "print(classification_report(y_train, cv_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(clust_count,np.array(target['\"Target\"']).reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # топ-20 признаков с весами из решающего леса\n",
    "fs = tfidf.get_feature_names() + count_char.get_feature_names() + list(X_train.columns)\n",
    "wfs = list(zip(fs,clf.feature_importances_))\n",
    "wfs = sorted(wfs,key=lambda x: x[1],reverse = True)\n",
    "for w in wfs[:20]:\n",
    "    print(w[0],w[1],sep=' - ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.9s finished\n"
     ]
    }
   ],
   "source": [
    "# logit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(class_weight={1:30,0:1},random_state=seed)\n",
    "cv_logit = cross_val_predict(logit, X_train_imp, y_train, cv = skf, verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7116\n",
      "7114\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(cv_logit))\n",
    "idx = X_train['First'].index\n",
    "for i,pr in enumerate(cv_logit):\n",
    "    if X_train['First'][idx[i]] == 0:\n",
    "        cv_logit[i] = 0\n",
    "print(np.sum(cv_logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.945591088178\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97     97487\n",
      "          1       0.29      0.83      0.43      2515\n",
      "\n",
      "avg / total       0.98      0.95      0.96    100002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# на кросс-валидации\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_train, cv_logit))\n",
    "print(classification_report(y_train, cv_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.7s finished\n"
     ]
    }
   ],
   "source": [
    "clf = RidgeClassifier(alpha=40,class_weight={1:30,0:1},random_state=seed)\n",
    "cv_ridge = cross_val_predict(clf, X_train_imp, y_train, cv = skf, verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10934\n",
      "9056\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(cv_ridge))\n",
    "idx = X_train['First'].index\n",
    "for i,pr in enumerate(cv_ridge):\n",
    "    if X_train['First'][idx[i]] == 0:\n",
    "        cv_ridge[i] = 0\n",
    "print(np.sum(cv_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.926871462571\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96     97487\n",
      "          1       0.24      0.85      0.37      2515\n",
      "\n",
      "avg / total       0.98      0.93      0.95    100002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(accuracy_score(y_train, cv_ridge))\n",
    "print(classification_report(y_train, cv_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    9.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   12.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   16.0s finished\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C=0.05,\n",
    "                class_weight={1:30,0:1},\n",
    "                random_state=seed)\n",
    "cv_svc = cross_val_predict(clf, X_train_imp, y_train, cv = skf, verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7360\n",
      "7354\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(cv_svc))\n",
    "idx = X_train['First'].index\n",
    "for i,pr in enumerate(cv_svc):\n",
    "    if X_train['First'][idx[i]] == 0:\n",
    "        cv_svc[i] = 0\n",
    "print(np.sum(cv_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.943691126177\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97     97487\n",
      "          1       0.29      0.84      0.43      2515\n",
      "\n",
      "avg / total       0.98      0.94      0.96    100002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(accuracy_score(y_train, cv_svc))\n",
    "print(classification_report(y_train, cv_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперименты с вероятностями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.02\n",
      "0.04\n",
      "0.06\n",
      "0.08\n",
      "0.1\n",
      "0.12\n",
      "0.14\n",
      "0.16\n",
      "0.18\n",
      "0.2\n",
      "0.22\n",
      "0.24\n",
      "0.26\n",
      "0.28\n",
      "0.3\n",
      "0.32\n",
      "0.34\n",
      "0.36\n",
      "0.38\n",
      "0.4\n",
      "0.42\n",
      "0.44\n",
      "0.46\n",
      "0.48\n",
      "0.5\n",
      "0.52\n",
      "0.54\n",
      "0.56\n",
      "0.58\n",
      "0.6\n",
      "0.62\n",
      "0.64\n",
      "0.66\n",
      "0.68\n",
      "0.7\n",
      "0.72\n",
      "0.74\n",
      "0.76\n",
      "0.78\n",
      "0.8\n",
      "0.82\n",
      "0.84\n",
      "0.86\n",
      "0.88\n",
      "0.9\n",
      "0.92\n",
      "0.94\n",
      "0.96\n",
      "0.98\n",
      "1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.96      0.98    107488\n",
      "          1       0.33      0.80      0.47      2576\n",
      "\n",
      "avg / total       0.98      0.96      0.97    110064\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC1\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score\n",
    "\n",
    "max_score = 0\n",
    "max_threshold = 0\n",
    "max_alpha = 0\n",
    "for alpha in np.linspace(0.0, 1.0, 51): #переберем числа от 0.01 до 0.99\n",
    "    print(alpha)\n",
    "    for threshold in np.linspace(0.4,1.0,31):\n",
    "        w = cv_pred * alpha + cv_logit * (1 - alpha) #подберем веса для двух моделей\n",
    "        w = np.where(w > threshold, 1, 0)\n",
    "        score = f1_score(y_train,w) * recall_score(y_train,w)\n",
    "        if score > max_score:\n",
    "            max_threshold = threshold\n",
    "            max_alpha = alpha\n",
    "            max_score = score\n",
    "\n",
    "\n",
    "cv_cum = cv_pred * max_alpha + cv_logit * (1 - max_alpha) #берем модели с весами, которые нашли выше\n",
    "cv_cum = np.where(cv_cum > max_threshold, 1, 0)\n",
    "print(classification_report(y_train,cv_cum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.68000000000000005)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_alpha, max_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Взвешенное голосование "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_cum = [int(round((cv_pred[i]*0.25 + cv_ridge[i]*0.25 + \n",
    "                 + cv_svc[i]*0.25 + cv_logit[i]*0.25))) for i in range(len(cv_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.947541049179\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97     97487\n",
      "          1       0.30      0.82      0.44      2515\n",
      "\n",
      "avg / total       0.98      0.95      0.96    100002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(accuracy_score(y_train, cv_cum))\n",
    "print(classification_report(y_train, cv_cum)) \n",
    "# было 30 86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "count = CountVectorizer(min_df = 10, ngram_range = (1,2))\n",
    "count_char = CountVectorizer(min_df = 10, ngram_range = (3,4),analyzer='char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#models\n",
    "forest = RandomForestClassifier(n_estimators=300,\n",
    "                                criterion='entropy',\n",
    "                                min_samples_leaf=5,\n",
    "                                class_weight = {1:30,0:1},\n",
    "                                random_state=seed)\n",
    "\n",
    "logit = LogisticRegression(class_weight={1:30,0:1},\n",
    "                             random_state=seed)\n",
    "\n",
    "\n",
    "ridge = RidgeClassifier(alpha=40,\n",
    "                        class_weight={1:30,0:1},\n",
    "                        random_state=seed)\n",
    "\n",
    "svc = LinearSVC(C=0.05,\n",
    "                class_weight={1:30,0:1},\n",
    "                random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(3, 4), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.fit(data['Text'])\n",
    "count_char.fit(data['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### без текстовых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.88      0.94     13594\n",
      "          1       0.14      0.78      0.24       337\n",
      "\n",
      "avg / total       0.97      0.88      0.92     13931\n",
      "\n",
      "logit\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91     13594\n",
      "          1       0.12      0.87      0.20       337\n",
      "\n",
      "avg / total       0.97      0.84      0.89     13931\n",
      "\n",
      "svc\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91     13594\n",
      "          1       0.11      0.86      0.20       337\n",
      "\n",
      "avg / total       0.97      0.83      0.89     13931\n",
      "\n",
      "ridge\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89     13594\n",
      "          1       0.10      0.90      0.18       337\n",
      "\n",
      "avg / total       0.98      0.80      0.87     13931\n",
      "\n",
      "Accuracy:\n",
      "0.837915440385\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.84      0.91     13594\n",
      "          1       0.12      0.86      0.20       337\n",
      "\n",
      "avg / total       0.97      0.84      0.89     13931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest.fit(X_train, y_train)\n",
    "logit.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "f_pred = forest.predict(X_test)\n",
    "l_pred = logit.predict(X_test)\n",
    "s_pred = svc.predict(X_test)\n",
    "r_pred = ridge.predict(X_test)\n",
    "\n",
    "idx = X_test.index\n",
    "for i,pr in enumerate(f_pred):\n",
    "    if X_test['First'][idx[i]] == 0:\n",
    "        f_pred[i] = 0\n",
    "        l_pred[i] = 0\n",
    "        s_pred[i] = 0\n",
    "        r_pred[i] = 0\n",
    "\n",
    "print('forest',classification_report(y_test,f_pred),sep='\\n')\n",
    "print('logit',classification_report(y_test,l_pred),sep='\\n')\n",
    "print('svc',classification_report(y_test,s_pred),sep='\\n')\n",
    "print('ridge',classification_report(y_test,r_pred),sep='\\n')\n",
    "\n",
    "cv_cum_test = [int(round((f_pred[i]*0.25 + r_pred[i]*0.25 +\n",
    "                 + s_pred[i]*0.25 + l_pred[i]*0.25))) for i in range(len(f_pred))]\n",
    "\n",
    "# на кросс-валидации\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, cv_cum_test))\n",
    "print(classification_report(y_test, cv_cum_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### все признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.95      0.97     13594\n",
      "          1       0.27      0.73      0.39       337\n",
      "\n",
      "avg / total       0.98      0.95      0.96     13931\n",
      "\n",
      "logit\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.95      0.97     13594\n",
      "          1       0.28      0.73      0.40       337\n",
      "\n",
      "avg / total       0.98      0.95      0.96     13931\n",
      "\n",
      "svc\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.95      0.97     13594\n",
      "          1       0.28      0.75      0.41       337\n",
      "\n",
      "avg / total       0.98      0.95      0.96     13931\n",
      "\n",
      "ridge\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.94      0.97     13594\n",
      "          1       0.26      0.80      0.39       337\n",
      "\n",
      "avg / total       0.98      0.94      0.95     13931\n",
      "\n",
      "Accuracy:\n",
      "0.952192950973\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.96      0.98     13594\n",
      "          1       0.30      0.73      0.42       337\n",
      "\n",
      "avg / total       0.98      0.95      0.96     13931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest.fit(X_train_count, y_train)\n",
    "logit.fit(X_train_count, y_train)\n",
    "svc.fit(X_train_count, y_train)\n",
    "ridge.fit(X_train_count, y_train)\n",
    "\n",
    "f_pred = forest.predict(X_test_count)\n",
    "l_pred = logit.predict(X_test_count)\n",
    "s_pred = svc.predict(X_test_count)\n",
    "r_pred = ridge.predict(X_test_count)\n",
    "\n",
    "idx = X_test.index\n",
    "for i,pr in enumerate(f_pred):\n",
    "    if X_test['First'][idx[i]] == 0:\n",
    "        f_pred[i] = 0\n",
    "        l_pred[i] = 0\n",
    "        s_pred[i] = 0\n",
    "        r_pred[i] = 0\n",
    "\n",
    "print('forest',classification_report(y_test,f_pred),sep='\\n')\n",
    "print('logit',classification_report(y_test,l_pred),sep='\\n')\n",
    "print('svc',classification_report(y_test,s_pred),sep='\\n')\n",
    "print('ridge',classification_report(y_test,r_pred),sep='\\n')\n",
    "\n",
    "cv_cum_test = [int(round((f_pred[i]*0.25 + r_pred[i]*0.25 +\n",
    "                 + s_pred[i]*0.25 + l_pred[i]*0.25))) for i in range(len(f_pred))]\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, cv_cum_test))\n",
    "print(classification_report(y_test, cv_cum_test))# на кросс-валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### все признаки + feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.95      0.97     13594\n",
      "          1       0.26      0.74      0.38       337\n",
      "\n",
      "avg / total       0.98      0.94      0.96     13931\n",
      "\n",
      "logit\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.95      0.97     13594\n",
      "          1       0.27      0.74      0.40       337\n",
      "\n",
      "avg / total       0.98      0.95      0.96     13931\n",
      "\n",
      "svc\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.95      0.97     13594\n",
      "          1       0.27      0.75      0.40       337\n",
      "\n",
      "avg / total       0.98      0.95      0.96     13931\n",
      "\n",
      "ridge\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97     13594\n",
      "          1       0.24      0.81      0.38       337\n",
      "\n",
      "avg / total       0.98      0.93      0.95     13931\n",
      "\n",
      "Accuracy:\n",
      "0.949321656737\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.95      0.97     13594\n",
      "          1       0.29      0.74      0.41       337\n",
      "\n",
      "avg / total       0.98      0.95      0.96     13931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest.fit(X_train_imp, y_train)\n",
    "logit.fit(X_train_imp, y_train)\n",
    "svc.fit(X_train_imp, y_train)\n",
    "ridge.fit(X_train_imp, y_train)\n",
    "\n",
    "f_pred = forest.predict(X_test_imp)\n",
    "l_pred = logit.predict(X_test_imp)\n",
    "s_pred = svc.predict(X_test_imp)\n",
    "r_pred = ridge.predict(X_test_imp)\n",
    "\n",
    "idx = X_test.index\n",
    "for i,pr in enumerate(f_pred):\n",
    "    if X_test['First'][idx[i]] == 0:\n",
    "        f_pred[i] = 0\n",
    "        l_pred[i] = 0\n",
    "        s_pred[i] = 0\n",
    "        r_pred[i] = 0\n",
    "\n",
    "print('forest',classification_report(y_test,f_pred),sep='\\n')\n",
    "print('logit',classification_report(y_test,l_pred),sep='\\n')\n",
    "print('svc',classification_report(y_test,s_pred),sep='\\n')\n",
    "print('ridge',classification_report(y_test,r_pred),sep='\\n')\n",
    "\n",
    "cv_cum_test = [int(round((f_pred[i]*0.25 + r_pred[i]*0.25 +\n",
    "                 + s_pred[i]*0.25 + l_pred[i]*0.25))) for i in range(len(f_pred))]\n",
    "\n",
    "# на кросс-валидации\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, cv_cum_test))\n",
    "print(classification_report(y_test, cv_cum_test))# на кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# записать таблицу в файл - всю таблицу со всеми признаками, предсказанием и реальными ответами\n",
    "texts = pd.concat((data.reset_index(drop=True), pd.DataFrame(cv_cum), pd.DataFrame(target)), axis = 1) \n",
    "texts.columns = [x if x != 0 else 'predicted' for x in texts.columns]\n",
    "texts.to_csv('predicted.csv',sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# записать только тестовую таблицу\n",
    "test_texts = pd.concat((test_data.reset_index(drop=True), pd.DataFrame(cv_cum_test), test_target), axis = 1) \n",
    "test_texts.columns = [x if x != 0 else 'predicted' for x in texts.columns]\n",
    "test_texts.to_csv('test_predicted.csv',sep=';',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучить на всех пьесах и записать модели в файлы pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "count = CountVectorizer(min_df = 10, ngram_range = (1,2))\n",
    "count_char = CountVectorizer(min_df = 10, ngram_range = (3,4),analyzer='char')\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=300,\n",
    "                                criterion='entropy',\n",
    "                                min_samples_leaf=5,\n",
    "                                class_weight = {1:30,0:1},\n",
    "                                random_state=seed)\n",
    "\n",
    "logit = LogisticRegression(class_weight={1:30,0:1},\n",
    "                             random_state=seed)\n",
    "\n",
    "ridge = RidgeClassifier(alpha=40,\n",
    "                        class_weight={1:30,0:1},\n",
    "                        random_state=seed)\n",
    "\n",
    "svc = LinearSVC(C=0.05,\n",
    "                class_weight={1:30,0:1},\n",
    "                random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113933"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.read_csv('train_data.csv', encoding = 'utf-8-sig', sep = ';')\n",
    "full_target = pd.read_csv('train_target.csv',encoding = 'utf-8-sig', sep = ';' )\n",
    "len(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count.fit(full_data['Text'])\n",
    "count_char.fit(full_data['Text'])\n",
    "\n",
    "pickle.dump(count,open('count.pickle','wb'))\n",
    "pickle.dump(count_char,open('count_char.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_full = count.transform(full_data['Text'])\n",
    "count_char_full = count_char.transform(full_data['Text'])\n",
    "X_full_data = full_data.drop(['Text','\"Text_id\"'],axis=1)\n",
    "full_data_sparse = csr_matrix(X_full_data)\n",
    "full_data_count = hstack((count_full,count_char_full,full_data_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest.fit(full_data_count, np.array(full_target['\"Target\"']).reshape(-1,))\n",
    "logit.fit(full_data_count, np.array(full_target['\"Target\"']).reshape(-1,))\n",
    "svc.fit(full_data_count, np.array(full_target['\"Target\"']).reshape(-1,))\n",
    "ridge.fit(full_data_count, np.array(full_target['\"Target\"']).reshape(-1,))\n",
    "\n",
    "pickle.dump(forest,open('forest.pickle','wb'))\n",
    "pickle.dump(logit,open('logit.pickle','wb'))\n",
    "pickle.dump(svc,open('svc.pickle','wb'))\n",
    "pickle.dump(ridge,open('ridge.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<113933x4929 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 277970 stored elements in Compressed Sparse Row format>,\n",
       " <113933x4929 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 277970 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_f = pickle.load(open('count.pickle','rb'))\n",
    "count_f_full = count_f.transform(full_data['Text'])\n",
    "\n",
    "count_full,count_f_full"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
